import os
import json
import glob
import shutil
import random
import os.path as osp

"""
æ•°æ®é›†åˆ’åˆ†ä¸ YOLO æ•°æ®é›†æè¿°æ–‡ä»¶ç”Ÿæˆè„šæœ¬

æœ¬è„šæœ¬ç”¨äºï¼š
- æ£€æŸ¥ `labels_dir`ï¼ˆæ ‡æ³¨ç›®å½•ï¼‰ä¸­æ˜¯å¦å·²åŒ…å«æ¯å¼ å›¾ç‰‡å¯¹åº”çš„ `.txt`ï¼ˆYOLO æ ¼å¼ï¼‰æ–‡ä»¶ï¼›
- æŒ‰å›¾ç‰‡åˆ—è¡¨éšæœºåˆ’åˆ†æ•°æ®é›†ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼‰ï¼š
  - 2-wayï¼ˆtrain/val = 8:2ï¼‰ï¼Œå½“ç”¨æˆ·è¾“å…¥ `n` æ—¶å¯ç”¨ï¼›
  - 3-wayï¼ˆtrain/test/val = 7:2:1ï¼‰ï¼Œå½“ç”¨æˆ·è¾“å…¥ `y` æˆ–ç›´æ¥å›è½¦ï¼ˆé»˜è®¤ï¼‰æ—¶å¯ç”¨ï¼›
- å°†åˆ’åˆ†ç»“æœå¤åˆ¶åˆ° `dataset_output` ä¸‹çš„ `images/{train,val,test}` å’Œ `labels/{train,val,test}` å­ç›®å½•ï¼›
- æ ¹æ® `classification_txt_path` ä¸­çš„ç±»åˆ«é¡ºåºç”Ÿæˆ `dataset.yaml`ï¼ŒåŒ…å« `path`ã€`train`ã€`val`ã€å¯é€‰ `test`ã€`nc`ã€`names` å­—æ®µï¼Œä¾› YOLO è®­ç»ƒä½¿ç”¨ã€‚

ä¸»è¦é…ç½®ï¼ˆä½äºæ–‡ä»¶é¡¶éƒ¨ï¼Œéœ€æ ¹æ®é¡¹ç›®è°ƒæ•´ï¼‰:
- `raw_data`ï¼šåŸå§‹æ•°æ®æ ¹ç›®å½•ï¼ˆè„šæœ¬é»˜è®¤ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ `raw_data/tomato`ï¼‰ã€‚
- `classification_txt_path`ï¼šåŒ…å«ç±»åˆ«åç§°çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼‰ï¼Œè„šæœ¬ä¼šæŒ‰æ­¤æ–‡ä»¶é¡ºåºç”Ÿæˆ `names`ã€‚
- `images_dir`ï¼šå›¾ç‰‡ç›®å½•ï¼ˆè„šæœ¬ä¼šåœ¨æ­¤æŸ¥æ‰¾å›¾ç‰‡ï¼Œæ”¯æŒå¸¸è§æ‰©å±•åå’Œå¤§å°å†™ï¼‰ã€‚
- `labels_dir`ï¼šæ ‡æ³¨ç›®å½•ï¼ŒæœŸæœ›åŒ…å«ä¸å›¾ç‰‡åŒåçš„ `.txt` æ–‡ä»¶ï¼ˆYOLO æ ¼å¼ï¼‰ã€‚
- `dataset_output`ï¼šåˆ’åˆ†åæ•°æ®è¾“å‡ºç›®å½•ï¼ˆåŒ…å« `images/` å’Œ `labels/` å­ç›®å½•ï¼‰ã€‚

è¿è¡Œæµç¨‹ï¼š
1. è¯»å–å¹¶åŠ è½½é…ç½®ï¼ˆè¯·ç¡®ä¿ `classification_txt_path` æŒ‡å‘æœ‰æ•ˆæ–‡ä»¶ï¼‰ã€‚
2. æ£€æŸ¥ `images_dir` ä¸‹çš„æ¯å¼ å›¾ç‰‡æ˜¯å¦åœ¨ `labels_dir` æœ‰å¯¹åº” `.txt`ï¼Œè‹¥ç¼ºå¤±è„šæœ¬ä¼šä¸­æ­¢å¹¶æ‰“å°ç¼ºå¤±é¡¹ã€‚
3. æç¤ºç”¨æˆ·é€‰æ‹©æ˜¯å¦ç”Ÿæˆ test é›†åˆï¼ˆé»˜è®¤ç”Ÿæˆ 3-way åˆ’åˆ†ï¼‰ï¼›æŒ‰æ¯”ä¾‹éšæœºåˆ’åˆ†å¹¶å¤åˆ¶å¯¹åº”å›¾ç‰‡ä¸ `.txt`ã€‚
4. åœ¨ `dataset_output` ä¸­ç”Ÿæˆ `dataset.yaml`ï¼›æ‰“å°ç»“æœè·¯å¾„ã€‚

ç¤ºä¾‹è¿è¡Œï¼š
    python 01_convert_labelme_to_yolo_seg.py

æ³¨æ„ï¼š
- æœ¬è„šæœ¬ä¸å†åŒ…å« JSONâ†’TXT çš„è½¬æ¢é€»è¾‘ï¼›å¦‚æœä½ çš„æ ‡æ³¨æ˜¯ JSONï¼ˆLabelme/ISATï¼‰ï¼Œè¯·å…ˆä½¿ç”¨ç›¸åº”è½¬æ¢å·¥å…·ç”Ÿæˆ YOLO æ ¼å¼çš„ `.txt`ã€‚
- è¯·ç¡®ä¿ `classification_txt_path` ä¸­çš„ç±»åˆ«åç§°ä¸æ ‡æ³¨æ–‡ä»¶ä¸­ä½¿ç”¨çš„ç±»åˆ«ä¸€è‡´ï¼Œå¦åˆ™æœ‰äº›æ ‡æ³¨ä¼šè¢«è·³è¿‡ã€‚
"""

# =====================
# é…ç½®åŒºï¼ˆå·²ä¿®æ”¹ï¼šæ”¯æŒå›¾ç‰‡ä¸æ ‡æ³¨åˆ†å¼€æ”¾åœ¨ä¸åŒæ–‡ä»¶å¤¹ï¼‰
# é»˜è®¤ä½¿ç”¨è„šæœ¬åŒçº§ç›®å½•ä¸‹çš„ `raw_data/` ä½œä¸ºæ ¹ç›®å½•ï¼Œå›¾ç‰‡ä¸æ ‡æ³¨åˆ†åˆ«æ”¾åœ¨
# `raw_datasets/{dataset_name}/images/` å’Œ `raw_datasets/{dataset_name}/labels/`ã€‚å¦‚éœ€å…¶ä»–è·¯å¾„ï¼Œè¯·ä¿®æ”¹ä¸‹é¢å˜é‡ã€‚
# =====================
dataset_process = input("å¤„ç†å¢å¼ºåæ•°æ®é›†è¿˜æ˜¯åŸå§‹æ•°æ®é›†ï¼Ÿ\r\nè¾“å…¥ y åˆ™å¤„ç†å¢å¼ºåçš„æ•°æ®é›†ï¼Œè¾“å…¥ n åˆ™å¤„ç†åŸå§‹æ•°æ®é›†ï¼š").strip().lower()
if dataset_process == "y":
    candidate_aug = "tomato_augment"  # å¢å¼ºåæ•°æ®é›†åç§°
    # å¦‚æœå¢å¼ºæ•°æ®é›†ä¸å­˜åœ¨ï¼Œåˆ™å›é€€ä¸ºåŸå§‹æ•°æ®é›†
    if not os.path.isdir(f"raw_datasets/{candidate_aug}"):
        print(f"âš ï¸ å¢å¼ºæ•°æ®é›†ä¸å­˜åœ¨: raw_datasets/{candidate_aug}ï¼Œå°†å¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ã€‚")
        # è¯•å›¾æ¨æ–­åŸå§‹æ•°æ®é›†åï¼ˆå»æ‰ `_augment` åç¼€ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤ 'tomato'
        base_name = candidate_aug.replace('_augment', '')
        if os.path.isdir(f"raw_datasets/{base_name}"):
            dataset_name = base_name
            print(f"ä½¿ç”¨åŸå§‹æ•°æ®é›†: {dataset_name}")
        else:
            dataset_name = 'tomato'
            print(f"æœªæ‰¾åˆ°åŸå§‹æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤: {dataset_name}ã€‚è¯·æ£€æŸ¥ raw_datasets/ ç›®å½•ã€‚")
    else:
        dataset_name = candidate_aug
else:
    dataset_name = "tomato"  # æ•°æ®é›†åç§°
    
raw_data = f"raw_datasets/{dataset_name}"  # åŸå§‹æ•°æ®æ ¹ç›®å½•
dataset_output = f"datasets/{dataset_name}"  # åˆ’åˆ†åæ•°æ®è¾“å‡ºç›®å½•
classification_txt_path = rf"raw_datasets/{dataset_name}/labels/classification.txt"
with open(classification_txt_path, 'r', encoding='utf-8') as f:
    class_list = [line.strip() for line in f if line.strip()]
# å›¾ç‰‡æ–‡ä»¶å¤¹ï¼ˆä¿®æ”¹ä¸ºä½ å®é™…çš„å›¾ç‰‡æ–‡ä»¶å¤¹åï¼Œä¾‹å¦‚ 'images' æˆ– 'JPEGImages'ï¼‰
images_dir = osp.join(raw_data, "images")
# æ ‡æ³¨æ–‡ä»¶å¤¹ï¼ˆåŒ…å« .json/.txtï¼Œä¾‹å¦‚ 'labels'ï¼‰
labels_dir = osp.join(raw_data, "labels")

random.seed(42)

# =====================
# ä¸»æµç¨‹
# =====================
def main():
    yolo_seg_splitter = YoloDatasetSplitter(dataset_name, images_dir, labels_dir, dataset_output, class_list)
    # -----------------------
    # æ­¥éª¤ 1ï¼šæ£€æŸ¥ TXT æ˜¯å¦å®Œæ•´
    # -----------------------
    yolo_seg_splitter.check_txt_files()

    # -----------------------
    # æ­¥éª¤ 2ï¼šæ•°æ®åˆ’åˆ†ï¼ˆæŒ‰å›¾ç‰‡åˆ—è¡¨åˆ’åˆ†å¹¶å¤åˆ¶å¯¹åº”çš„ TXTï¼‰
    # -----------------------
    yolo_seg_splitter.dataset_split()
    # print("æ­¥éª¤2ï¼šå‡†å¤‡åˆ’åˆ†æ•°æ®é›†...")

    # -----------------------
    # æ­¥éª¤ 3ï¼šç”Ÿæˆ dataset YAML æ–‡ä»¶
    # -----------------------
    yolo_seg_splitter.generate_yaml()


class YoloDatasetSplitter:
    def __init__(self, dataset_name, images_dir, labels_dir, dataset_output, class_list):
        self.dataset_name = dataset_name
        self.images_dir = images_dir
        self.labels_dir = labels_dir
        self.dataset_output = dataset_output
        self.class_list = class_list
        self.pic_formats = [".jpeg", ".JPEG", ".jpg", ".JPG", ".png", ".PNG", ".bmp", ".BMP", ".tif", ".TIF", ".tiff", ".TIFF", ".webp", ".WEBP"]
        self.image_files = []
        
        self.is_testDataset_required = False
        
        for pic_format in self.pic_formats:
            self.image_files = self.image_files + glob.glob(osp.join(self.images_dir, f"*{pic_format}"))

    def make_yolo_dirs(self):
        """åˆ›å»º YOLO æ‰€éœ€ç›®å½•"""
        dirs = ["images/train", "images/val", "labels/train", "labels/val"]
        if self.is_testDataset_required:
            dirs.extend(["images/test", "labels/test"])
        for d in dirs:
            path = osp.join(self.dataset_output, d)
            if not osp.exists(path):
                os.makedirs(path)
        print("âœ… ç›®å½•æ£€æŸ¥å®Œæˆ")


    def find_image(self, base):
        """åœ¨ `images_dir` ä¸­æŸ¥æ‰¾å›¾ç‰‡ï¼Œæ”¯æŒå¤šç§åç¼€ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ã€‚

        ä¼˜å…ˆè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„å¸¸è§å›¾ç‰‡æ–‡ä»¶ã€‚
        """
        # å°è¯•ç²¾ç¡®åç¼€åŒ¹é…ï¼ˆå¸¸è§å°å†™åç¼€ï¼‰
        for ext in self.pic_formats:
            img = osp.join(self.images_dir, base + ext)
            if osp.exists(img):
                return img

        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç”¨ glob åŒ¹é…ä»»æ„æ‰©å±•å¹¶æ£€æŸ¥æ‰©å±•æ˜¯å¦ä¸ºå›¾ç‰‡æ ¼å¼ï¼ˆå¤§å°å†™å…¼å®¹ï¼‰
        candidates = glob.glob(osp.join(self.images_dir, base + ".*"))
        for c in candidates:
            ext = osp.splitext(c)[1].lower()
            if ext in self.pic_formats:
                return c

        return None
    
    def copy_split(self, basenames, subset_name):
        for base in basenames:
            img_path = self.find_image(base)
            if img_path is None:
                print(f"âš  æ‰¾ä¸åˆ°å›¾ç‰‡ï¼š{base}ï¼Œå·²è·³è¿‡")
                continue
            dst_img = osp.join(self.dataset_output, "images", subset_name, osp.basename(img_path))
            shutil.copy(img_path, dst_img)

            src_txt = osp.join(self.labels_dir, base + ".txt")
            dst_txt = osp.join(self.dataset_output, "labels", subset_name, base + ".txt")
            if osp.exists(src_txt):
                shutil.copy(src_txt, dst_txt)
            else:
                print(f"âš  æœªæ‰¾åˆ°æ ‡æ³¨ TXTï¼š{base}.txtï¼ˆåœ¨ labels_dir ä¸­ï¼‰ï¼Œå·²è·³è¿‡ï¼‰")
    
    def check_txt_files(self):
        """æ£€æŸ¥æ¯å¼ å›¾ç‰‡æ˜¯å¦éƒ½æœ‰å¯¹åº”çš„ TXT æ–‡ä»¶"""
        for img in self.image_files:
            base = osp.splitext(osp.basename(img))[0]
            txt_path = osp.join(self.labels_dir, base + ".txt")
            if not osp.exists(txt_path):
                print(f"âŒ ç¼ºå°‘ TXT æ–‡ä»¶ï¼ˆåœ¨æ ‡æ³¨æ–‡ä»¶å¤¹ä¸­ï¼‰ï¼š{base}.txt")
                return False
        return True
    
    def dataset_split(self):
        # è·å–æ‰€æœ‰å›¾ç‰‡ basenames
        bases = [osp.splitext(osp.basename(p))[0] for p in self.image_files]
        if not bases:
            print("âŒ æœªåœ¨ images_dir ä¸­æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼Œæ— æ³•åˆ’åˆ†æ•°æ®é›†ã€‚")
            return

        # ç”¨æˆ·é€‰æ‹©æ˜¯å¦åŒ…å« test é›†åˆ
        opt_test = input("æ˜¯å¦åˆ’åˆ† test é›†åˆï¼Ÿ\r\nå›è½¦æˆ–è¾“å…¥ y åˆ™åˆ’åˆ† train:test:val=7:2:1ï¼Œè¾“å…¥ n åˆ™åªåˆ’åˆ† train:val=8:2ï¼š(y/n, default y)ï¼š").strip().lower()
        self.is_testDataset_required = (opt_test != "n")
        self.make_yolo_dirs()

        random.shuffle(bases)
        if self.is_testDataset_required:  
            n = len(bases)
            n_train = int(n * 0.7)
            n_test = int(n * 0.2)
            train_bases = bases[:n_train]
            test_bases = bases[n_train:n_train + n_test]
            val_bases = bases[n_train + n_test:]
            print(f"â¡ æ ·æœ¬æ€»æ•°: {n}ï¼Œè®­ç»ƒ: {len(train_bases)}ï¼Œæµ‹è¯•: {len(test_bases)}ï¼ŒéªŒè¯: {len(val_bases)}")
        else:
            n = len(bases)
            n_train = int(n * 0.8)
            train_bases = bases[:n_train]
            val_bases = bases[n_train:]
            test_bases = []
            print(f"â¡ æ ·æœ¬æ€»æ•°: {n}ï¼Œè®­ç»ƒ: {len(train_bases)}ï¼ŒéªŒè¯: {len(val_bases)} (æ— æµ‹è¯•é›†)")

        # æ‰§è¡Œå¤åˆ¶
        self.copy_split(train_bases, "train")
        if self.is_testDataset_required:
            self.copy_split(test_bases, "test")
        self.copy_split(val_bases, "val")

        print(f"ğŸ‰ æ•°æ®åˆ’åˆ†å®Œæˆï¼æ‰€æœ‰æ•°æ®å·²å­˜å…¥ {self.dataset_output}/ ç›®å½•")
        
    def generate_yaml(self):
        # ç”Ÿæˆ dataset YAML æ–‡ä»¶
        yaml_path = osp.join(self.dataset_output, f"{self.dataset_name}.yaml")
        dataset_path = self.dataset_name.replace('\\', '/')
        lines = []
        lines.append(f'# YOLO æ•°æ®é›†æè¿°æ–‡ä»¶ï¼Œä»…é€‚é… Ultralytics')
        lines.append(f'path: "{dataset_path}"')
        lines.append("")
        lines.append("train: images/train")
        lines.append("val: images/val")
        if self.is_testDataset_required:
            lines.append("test: images/test")
        lines.append("")
        lines.append(f"nc: {len(self.class_list)}")
        lines.append("names:")
        for i, name in enumerate(self.class_list):
            lines.append(f"  {i}: {name}")
        lines.append("")
        with open(yaml_path, 'w', encoding='utf-8') as yf:
            yf.write('\n'.join(lines))

        print(f"âœ… å·²ç”Ÿæˆ YAML æ–‡ä»¶ï¼š{yaml_path}")


if __name__ == "__main__":
    main()
